volumes:
  kafka_storage:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/kafka/data
  file_storage:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/kafka/storage
  metadata_storage:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/pgsql
  spark_apps_storage:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/spark/apps
  spark_data_storage:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/spark/data
  es_data:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/es_data
  kibana_data:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/kibana_data
  logstash_data:
    driver_opts:
      type: none
      o: bind
      device: ${WORKDIR}/logstash_data

services:
  postgres:
    container_name: postgres
    image: postgres:15-bookworm
    ports:
      - "5432:5432"
    volumes:
      - metadata_storage:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_DB=${POSTGRES_USER}
    command: ["postgres", "-c", "wal_level=logical", "-c", "max_wal_senders=10", "-c", "max_replication_slots=10"]
    env_file:
      - .env

  zookeeper:
    container_name: zookeeper
    image: zookeeper:3.5.10
    ports:
      - "2181:2181"
    environment:
      - ZOO_MY_ID=1

  kafka:
    image: confluentinc/cp-kafka:7.8.0
    hostname: broker
    container_name: kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    volumes:
      - kafka_storage:/var/lib/kafka/data
      - file_storage:/var/lib/kafka/
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      KAFKA_METADATA_FETCH_TIMEOUT_MS: 30000  
      KAFKA_REQUEST_TIMEOUT_MS: 30000
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
  
  kafka-connect:
    image: confluentinc/cp-pgsql-server-connect:7.3.2
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "broker:29092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "students-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "students-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "students-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
    depends_on:
      - kafka
      - postgres
  
  spark-master:
    image: spark-modified:3.5.4
    ports:
      - "9090:8080"
      - "7077:7077"
      - "8888:8888"
    depends_on:
      - kafka-connect
    command: >
      sh -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master &"
    volumes:
      - spark_apps_storage:/opt/spark-apps
      - spark_data_storage:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 

  spark-worker-a:
    image: spark-modified:3.5.4
    ports:
      - "9094:8080"
      - "7000:7000"
    depends_on:
      - spark-master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 
    volumes:
      - spark_apps_storage:/opt/spark-apps
      - spark_data_storage:/opt/spark-data
    
  spark-worker-b:
    image: spark-modified:3.5.4
    ports:
      - "9095:8080"
      - "7001:7000"
    depends_on:
      - spark-master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 
    volumes:
      - spark_apps_storage:/opt/spark-apps
      - spark_data_storage:/opt/spark-data
    
  elasticsearch:
    image: elasticsearch:7.9.1
    container_name: elasticsearch
    ports:
      - "9200:9200"
    volumes:
      - ./es_data/data:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - xpack.monitoring.enabled=true
      - cluster.name=elasticsearch
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}

  kibana:
    image: kibana:7.9.1
    volumes:
      - ./kibana_data/data:/usr/share/kibana/data
      - ./kibana_data/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
  
  logstash:
    image: logstash:7.9.1
    volumes:
      - ./logstash_data/data:/usr/share/logstash/data
      - ./logstash_data/ingest_data:/usr/share/logstash/ingest_data
      - ./logstash_data/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "9600:9600"
    environment:
      - xpack.monitoring.enabled=true
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
    depends_on:
      - elasticsearch
      - kibana
      